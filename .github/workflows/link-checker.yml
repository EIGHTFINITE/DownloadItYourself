name: Check Links

on:
  push:
  pull_request:
  schedule:
    - cron: '0 */4 * * *'

env:
  CI: true

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@master
    - uses: peter-evans/link-checker@master
      with:
        args: '-r -t 300 -x ^https?:\/\/(www\.curseforge\.com|www\.npmjs\.com|web\.archive\.org|www\.minecraftforum\.net) -v README.html'
      env:
        LINKCHECKER_OUTPUT_DIR: '.'
        LINKCHECKER_OUTPUT_FILENAME: 'link-checker-out.txt'
    - name: Output
      shell: bash
      run: |
        # curseforge.com, npmjs.com, web.archive.org, and minecraftforum.net links have been skipped because they block robots.
        if [[ $(cat link-checker-out.txt | grep -P '^(\tERROR|\t\t)' | tee /dev/stderr | head -c1 | wc -c) -ne 0 ]]
          then exit 1
        fi
